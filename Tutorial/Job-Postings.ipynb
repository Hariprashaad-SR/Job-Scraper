{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f71b4b2c",
   "metadata": {},
   "source": [
    "<h1><center>Tutorial on Web-scraping</center></h1>  \n",
    "<center>By <b>HARIPRASHAAD SR</b></center>\n",
    "<center>Student</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4b1456",
   "metadata": {},
   "source": [
    "> **TOPIC**      : _Scraping Job Posting_  \n",
    "> **TOOLS USED** : _Beautiful Soup_  \n",
    "> **DIFFICULTY** : _Beginner_  \n",
    "> **DOMAIN**     : _Web scraping_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ab6c3",
   "metadata": {},
   "source": [
    "## What is Web scraping ?\n",
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications. There are many different ways to perform web scraping to obtain data from websites. These include using online services, particular API’s or even creating your code for web scraping from scratch. Web scraping is a technique for extracting data from websites, transforming unstructured web content into a structured format. Utilizing tools like BeautifulSoup and Scrapy in Python, web scraping involves navigating web pages, selecting relevant HTML elements, and retrieving desired information. It enables automated data collection from diverse sources, empowering users to extract real-time data, monitor changes, and analyze trends. While a powerful tool for information retrieval, ethical considerations and adherence to website terms of service are paramount. Web scraping finds applications in data mining, market research, and building datasets for machine learning and analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f08de02",
   "metadata": {},
   "source": [
    "## Objective of the Project\n",
    "The objective of this web scraping project is to automate the collection of job postings from the official portal of the Government of Tamil Nadu using `Beautiful Soup` and `requests` in `python`. The primary goal is to develop a web scraping script that extracts detailed information from each job posting, including job titles, departments, locations, eligibility criteria, application deadlines, and other pertinent details. The project aims to structure the extracted data into a well-organized format, such as a dataset , facilitating easy analysis and reference. Additionally, the scraping script will be designed to run periodically, ensuring that the job postings data remains up-to-date.\n",
    "\n",
    "Comprehensive documentation will be provided for users, offering instructions on interacting with the data and understanding the presented information.\n",
    "> The project will strictly adhere to ethical standards and comply with the terms of use of the Government of Tamil Nadu's portal, respecting robots.txt rules and avoiding excessive requests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58a7841",
   "metadata": {},
   "source": [
    "## Libraries used\n",
    "- ### pandas:\n",
    "Pandas is a Python library for data manipulation and analysis, featuring powerful data structures like Series and DataFrame. Widely used in data science, it simplifies tasks such as cleaning, transforming, and visualizing structured data. With seamless integration and an intuitive interface, Pandas is essential for efficient data handling and analysis in Python.  \n",
    "**For creating Dataframes and csv files**\n",
    "- ### numpy:\n",
    "NumPy is a foundational Python library for numerical computing, providing support for large, multi-dimensional arrays and matrices. Essential for scientific and mathematical applications, it offers efficient operations on arrays, linear algebra functions, and tools for integrating with other data analysis libraries. NumPy is a cornerstone in the Python scientific computing ecosystem.  \n",
    "**For manipulating with arrays**\n",
    "- ### requests:\n",
    "The requests module allows you to **send HTTP requests in Python**, which is useful for interacting with web APIs or web scraping.\n",
    "The requests module is easy to use and well-documented, making it a good choice for beginners. \n",
    "The request module provides access to the various HTTP methods (GET, POST, PUT, DELETE) as well as many other popular request headers and parameters. This access makes it easy to handle common tasks, such as retrieving data from a server or creating customized responses in response to user actions.\n",
    "- ### BeautifulSoup:\n",
    "Beautiful Soup is a Python library for **parsing structured data**. It allows you to interact with HTML in a similar way to how you interact with a web page using developer tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b0601",
   "metadata": {},
   "source": [
    "## Steps involved in the project\n",
    "- Importing libraries\n",
    "- Getting the base url of the Job Posting website\n",
    "- Requesting the website for the HTML contents of the page using `request` package\n",
    "- Using the `BeautifulSoup` library, parse the contents\n",
    "- Search the HTML content to retrieve info on job postings, company name, posted date, requirements, city , etc...\n",
    "- Update these info into a Dataframe using `pandas` library\n",
    "- Extract the CSV file of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69852294",
   "metadata": {},
   "source": [
    "### STEP - 0 : Working Environment\n",
    "Make Sure you all have a `python - 3.7` or higher version and `pip` installed on your system. Open a python IDE of your own choice. And make sure you install the `requirement.txt` file by typing the following in your terminal.  \n",
    "  \n",
    "`pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef0555f",
   "metadata": {},
   "source": [
    "### STEP - 1 : Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad10c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbc7b16",
   "metadata": {},
   "source": [
    "### STEP - 2 : Job Posting Website\n",
    "We will find the Job posting from the `https://www.tnprivatejobs.tn.gov.in/Home/jobs`(Government of Tamil Nadu) and scrap through its contents\n",
    "\n",
    "![](https://imgur.com/NpqPyqh.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8139816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.tnprivatejobs.tn.gov.in/Home/jobs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17dd68a",
   "metadata": {},
   "source": [
    "We have around 280 Job posting in this website posted across 28 pages. And these webpages have their address as  \n",
    "<b>base_url + \"/\" + [10 , 20 ,30 ,...., 280]</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff64c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.tnprivatejobs.tn.gov.in/Home/jobs',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/10',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/20',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/30',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/40',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/50',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/60',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/70',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/80',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/90',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/100',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/110',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/120',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/130',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/140',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/150',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/160',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/170',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/180',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/190',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/200',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/210',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/220',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/230',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/240',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/250',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/260',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/270',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/Home/jobs/280']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list to store all the urls\n",
    "urls = [] \n",
    "\n",
    "# Appending the base url to the list\n",
    "urls.append(base_url)\n",
    "\n",
    "for i in range(10,281,10):\n",
    "    # Appending all urls to the list\n",
    "    urls.append(f\"{base_url}/{i}\")\n",
    "    \n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404bf15f",
   "metadata": {},
   "source": [
    "### STEP - 3 : Requesting the website \n",
    "We will request the website for the HTML content of the searching page using the `request` package  \n",
    "  \n",
    "> We will use only the `base_url` to learn about some basic concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79dcbd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request successful\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    page = requests.get(base_url)\n",
    "\n",
    "    # Check if the request was successful(status code 200)\n",
    "    if page.status_code == 200:\n",
    "        print(\"Request successful\")\n",
    "    else:\n",
    "        print(f\"Request failed with status code {page.status_code}\")\n",
    "\n",
    "except requests.RequestException as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c15b9",
   "metadata": {},
   "source": [
    "We can see the returned content by printing the `page`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dada6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfee726",
   "metadata": {},
   "source": [
    "### STEP - 4 : Parse the contents\n",
    "Using the BeautifulSoup library, parse the contents and store it in a variable `response` which will be used throughout this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef4a9e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the parsed contents\n",
    "response = BeautifulSoup(page.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10233d35",
   "metadata": {},
   "source": [
    "**This will return the html page of the scraped website**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79daafbf",
   "metadata": {},
   "source": [
    "`print(response)`   \n",
    "\n",
    "will list the entire `HTML` content of the webpage, which is very large. So, that line is not executed.  \n",
    "If you want to view it you can execute that line.\n",
    "\n",
    "Sample output of the above line:\n",
    "![](https://imgur.com/XtQBSTH.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb22b0",
   "metadata": {},
   "source": [
    "**Consolidation of Step 3 and Step 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "938b4119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(url):\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "\n",
    "        # Check if the request was successful(status code 200)\n",
    "        if page.status_code == 200:\n",
    "            print(\"Request successful\")\n",
    "\n",
    "            # Storing the parsed contents\n",
    "            response = BeautifulSoup(page.text,\"html.parser\")\n",
    "        else:\n",
    "            print(f\"Request failed with status code {page.status_code}\")\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    else:\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7601a4d1",
   "metadata": {},
   "source": [
    "### STEP - 5 : Scraping through the returned web-content\n",
    "- Job\n",
    "- Company name\n",
    "- City\n",
    "- Role Description\n",
    "- Field\n",
    "- Requirement\n",
    "- Salary\n",
    "- Open date\n",
    "- Close date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe49450",
   "metadata": {},
   "source": [
    "Before going forward, We will learn about how basic web scraping works.  \n",
    "Our required details are present in the `response` in `HTML` format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8e98f",
   "metadata": {},
   "source": [
    "### Step - 5.1 : Scraping the Job Title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c117b3dc",
   "metadata": {},
   "source": [
    "Right Click on the mouse on your web-page and click on `Inspect Element`, to see the `HTML`content of the webpage. In the below figure it is clear that the job titles are present inside the `<h4>` tags. So we would find all the `h4`tags using the `find_all( )` function\n",
    "\n",
    "![](https://imgur.com/fWshCmn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79181ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h4 class=\"panel-title\"> <a class=\"collapsed\" data-parent=\"#accordion\" data-toggle=\"collapse\" href=\"#jobsbycity\">Jobs By Location</a> </h4>,\n",
       " <h4 class=\"panel-title\"> <a class=\"collapsed\" data-parent=\"#accordion\" data-toggle=\"collapse\" href=\"#jobsbytype\">Jobs By Type</a> </h4>,\n",
       " <h4 class=\"panel-title\"> <a class=\"collapsed\" data-parent=\"#accordion\" data-toggle=\"collapse\" href=\"#jobsbysector\">Jobs By Sector</a> </h4>,\n",
       " <h4 class=\"panel-title\"> <a class=\"collapsed\" data-parent=\"#accordion\" data-toggle=\"collapse\" href=\"#jobsbygender\">Jobs By Gender</a> </h4>,\n",
       " <h4 class=\"panel-title\"> <a class=\"collapsed\" data-parent=\"#accordion\" data-toggle=\"collapse\" href=\"#jobsbyexperience\">Jobs By Experience</a> </h4>,\n",
       " <h4 class=\"panel-title\"> <a class=\"collapsed\" data-parent=\"#accordion\" data-toggle=\"collapse\" href=\"#jobsbysalary\">Salary Range</a> </h4>,\n",
       " <h4 class=\"panel-title\"> <a class=\"collapsed\" data-parent=\"#accordion\" data-toggle=\"collapse\" href=\"#jobsbytopcomp\">Top Companies</a> </h4>,\n",
       " <h4 class=\"panel-title\"> <a class=\"collapsed\" data-parent=\"#accordion\" data-toggle=\"collapse\" href=\"#jobsbyedutype\">Qualification</a> </h4>,\n",
       " <h4 class=\"panel-title\"> <a class=\"collapsed\" data-parent=\"#accordion\" data-toggle=\"collapse\" href=\"#jobsbytodisability\">Differently Abled</a> </h4>,\n",
       " <h4>\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23102202344326050\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tDigital Marketing Executive \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
       " </h4>,\n",
       " <h4>\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23111702045226171\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tGraphic Desginer \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
       " </h4>,\n",
       " <h4>\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23111702230126397\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tVIDEO JOCKEY \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
       " </h4>,\n",
       " <h4>\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23112109532337594\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tBus Captain \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
       " </h4>,\n",
       " <h4>\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23072512412210335\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tElectrical design engineer \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
       " </h4>,\n",
       " <h4>\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23083104491031380\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tBILLING EXECUTIVES \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
       " </h4>,\n",
       " <h4>\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23090602402603079\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tSewing Machine Operator  - பெண்களுக்கான வேலைவாய்ப்பு  \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
       " </h4>,\n",
       " <h4>\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23091105483508313\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tProject Manager/Project In-charge/ Project Engineer/ Executive \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
       " </h4>,\n",
       " <h4>\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23091210083521943\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tGraphic Desginer \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
       " </h4>,\n",
       " <h4>\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23091210132821264\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tGraphic Designer &amp; DTP Operator \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
       " </h4>,\n",
       " <h4 class=\"modal-title text-center\">Terms &amp; Conditions</h4>,\n",
       " <h4 class=\"modal-title\">Terms &amp; Conditions</h4>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find_all() is used to find all the occurance of the search element - <h4> tags\n",
    "all_h4 = response.find_all('h4')\n",
    "all_h4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b067a219",
   "metadata": {},
   "source": [
    "All the Job titles are within the `<a>`tags with the uniqe `style = 'color: #02b44a;'`. We would scrap these information using the `find( )` function which gives the first occurance of the search element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d414331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23102202344326050\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tDigital Marketing Executive \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23111702045226171\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tGraphic Desginer \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23111702230126397\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tVIDEO JOCKEY \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23112109532337594\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tBus Captain \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23072512412210335\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tElectrical design engineer \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23083104491031380\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tBILLING EXECUTIVES \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23090602402603079\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tSewing Machine Operator  - பெண்களுக்கான வேலைவாய்ப்பு  \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23091105483508313\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tProject Manager/Project In-charge/ Project Engineer/ Executive \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23091210083521943\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tGraphic Desginer \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23091210132821264\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tGraphic Designer &amp; DTP Operator \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find() is used to find the first occurance of the search element - <a> tags\n",
    "all_a_tags = [h4.find('a',style = 'color: #02b44a;') for h4 in all_h4]\n",
    "all_a_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd13dab",
   "metadata": {},
   "source": [
    "**Now we have all the `a` tags, but some values are `None`. We would like to get the contents of the `a` tags that are not `None` using the `.text` function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9248249d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDigital Marketing Executive \\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t',\n",
       " '\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGraphic Desginer \\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t',\n",
       " '\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tVIDEO JOCKEY \\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t',\n",
       " '\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tBus Captain \\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t',\n",
       " '\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tElectrical design engineer \\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t',\n",
       " '\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tBILLING EXECUTIVES \\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t',\n",
       " '\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tSewing Machine Operator  - பெண்களுக்கான வேலைவாய்ப்பு  \\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t',\n",
       " '\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tProject Manager/Project In-charge/ Project Engineer/ Executive \\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t',\n",
       " '\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGraphic Desginer \\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t',\n",
       " '\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGraphic Designer & DTP Operator \\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .text is used to strip of the contents of a particular tag - <a> tag\n",
    "job_titles = [a.text for a in all_a_tags if a != None]\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1241925e",
   "metadata": {},
   "source": [
    "**Though we have extracted the job titles, they are not clean. So, we would create a function `clean_text` to clean the text by removing the escape characters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c1d552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # This function removes all the escape characters - ['\\n' ,'\\t' , '\\r']\n",
    "    cleaned_text = text.replace('\\t','').replace('\\n','').replace('\\r','').strip()\n",
    "    \n",
    "    # This removes the blank spaces\n",
    "    cleaned_text = ' '.join(cleaned_text.split()) \n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62ce3bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Digital Marketing Executive',\n",
       " 'Graphic Desginer',\n",
       " 'VIDEO JOCKEY',\n",
       " 'Bus Captain',\n",
       " 'Electrical design engineer',\n",
       " 'BILLING EXECUTIVES',\n",
       " 'Sewing Machine Operator - பெண்களுக்கான வேலைவாய்ப்பு',\n",
       " 'Project Manager/Project In-charge/ Project Engineer/ Executive',\n",
       " 'Graphic Desginer',\n",
       " 'Graphic Designer & DTP Operator']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the scraped job titles using the clean_text function\n",
    "job_titles = [clean_text(title) for title in job_titles]\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67564213",
   "metadata": {},
   "source": [
    "###### The final process of the Step5.1 is to consolidate everything inside a function `scrap_title()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76adbdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_title(response):\n",
    "    #This function is used to scrap the job_titles from each webpage\n",
    "    \n",
    "    # find_all() is used to find all the occurance of the search element - <h4> tags\n",
    "    all_h4 = response.find_all('h4')\n",
    "    \n",
    "    # find() is used to find the first occurance of the search element - <a> tags\n",
    "    all_a_tags = [h4.find('a',style = 'color: #02b44a;') for h4 in all_h4]\n",
    "    \n",
    "    # .text is used to strip of the contents of a particular tag - <a> tag\n",
    "    job_titles = [a.text for a in all_a_tags if a != None]\n",
    "    \n",
    "    # Clean the scraped job titles using the clean_text function\n",
    "    job_titles = [clean_text(title) for title in job_titles]\n",
    "    \n",
    "    return job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1c84aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Digital Marketing Executive',\n",
       " 'Graphic Desginer',\n",
       " 'VIDEO JOCKEY',\n",
       " 'Bus Captain',\n",
       " 'Electrical design engineer',\n",
       " 'BILLING EXECUTIVES',\n",
       " 'Sewing Machine Operator - பெண்களுக்கான வேலைவாய்ப்பு',\n",
       " 'Project Manager/Project In-charge/ Project Engineer/ Executive',\n",
       " 'Graphic Desginer',\n",
       " 'Graphic Designer & DTP Operator']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrap_title(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5c5c91",
   "metadata": {},
   "source": [
    "### STEP 5.2 : Scraping through each Job \n",
    "Now we have completed our first web-scraping, we would speed up things.  \n",
    "In this step, we will go through webpages for each job and scrap the required information\n",
    "\n",
    "![](https://imgur.com/FJN7xwW.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eebdee9",
   "metadata": {},
   "source": [
    "**We would like to visit each job's webpage and extract the contents. For that to happen, first we want to collect the urls of the webpages of each job.**\n",
    "\n",
    "![](https://imgur.com/li5SJJU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628af1e1",
   "metadata": {},
   "source": [
    "**Looking at the image above, It is sure that all the links are present in the same `<a>` tags that we used to retrieve the `job_titles`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77a5cab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23102202344326050\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tDigital Marketing Executive \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23111702045226171\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tGraphic Desginer \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23111702230126397\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tVIDEO JOCKEY \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23112109532337594\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tBus Captain \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23072512412210335\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tElectrical design engineer \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23083104491031380\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tBILLING EXECUTIVES \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23090602402603079\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tSewing Machine Operator  - பெண்களுக்கான வேலைவாய்ப்பு  \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23091105483508313\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tProject Manager/Project In-charge/ Project Engineer/ Executive \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23091210083521943\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tGraphic Desginer \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " <a href=\"https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23091210132821264\" style=\"color: #02b44a;\">\n",
       " \t\t\t\t\t\t\t\t\t\t\tGraphic Designer &amp; DTP Operator \n",
       " \n",
       " \t\t\t\t\t\t\t\t\t\t\t\n",
       " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving all the <a> tags with a link to each jobs\n",
    "all_h4s = response.find_all(\"h4\")\n",
    "all_a_tag = [h4.find('a',style = 'color: #02b44a;') for h4 in all_h4s]\n",
    "all_a_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caacf83f",
   "metadata": {},
   "source": [
    "**Now for each of these `<a>` tags that is not `None`, we will get the link to each job description. \n",
    "For this purpose we would use the `.attrs['href']` function that will get the href attribute from the `<a>`tags.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfaeca6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23102202344326050',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23111702045226171',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23111702230126397',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23112109532337594',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23072512412210335',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23083104491031380',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23090602402603079',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23091105483508313',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23091210083521943',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23091210132821264']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .attrs[] is used to retrieve the mentioned tag out from a HTML source\n",
    "href = [a.attrs['href'] for a in all_a_tag if a != None]\n",
    "href"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fd5e42",
   "metadata": {},
   "source": [
    "**Now we have have come to the end of the Step 5.2, we will consolidate this step using a function `get_href()`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df8d7aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_href(response):\n",
    "    # This function is used to get the links to each job in a web-page\n",
    "    \n",
    "    # Retrieving all the <a> tags with a link to each jobs\n",
    "    all_h4s = response.find_all(\"h4\")\n",
    "    all_a_tag = [h4.find('a',style = 'color: #02b44a;') for h4 in all_h4s]\n",
    "    \n",
    "    # .attrs[] is used to retrieve the mentioned tag out from a HTML source\n",
    "    href = [a.attrs['href'] for a in all_a_tag if a != None]\n",
    "    \n",
    "    return href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de76d121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23102202344326050',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23111702045226171',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23111702230126397',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23112109532337594',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23072512412210335',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23083104491031380',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23090602402603079',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23091105483508313',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23091210083521943',\n",
       " 'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23091210132821264']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_href(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8dba0a",
   "metadata": {},
   "source": [
    "### STEP 5.3 : Getting contents for each job\n",
    "We would get the contents from each of the webpages that we retrieved in the last step about each job. Initially we would only use the first link.  \n",
    "- Field\n",
    "- Desription\n",
    "- Salary\n",
    "- Qualification\n",
    "- City\n",
    "- Landmark\n",
    "- Requirements(Gender, Age, Openings, Experience,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "926e6112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising all the variables to store the scraped content\n",
    "gender = age = opening = exp = city = landmark = field = desc = sal = qual = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c0ff2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.tnprivatejobs.tn.gov.in/candidate/Home/ca_jobfair_single/23102202344326050'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first URL\n",
    "url_1 = get_href(response)[0]\n",
    "url_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d5a48a",
   "metadata": {},
   "source": [
    "**Now we will request and parse the `url_1` using the `parse()` function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b78d4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request successful\n"
     ]
    }
   ],
   "source": [
    "# Parse it using the parse() function\n",
    "res_1 = parse(url_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f544297",
   "metadata": {},
   "source": [
    "**Since, our contents are in the `div` tag with a unique class name `location`. We will do the exact same steps that we have done during the job_title scraping.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b28a3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n   Media & Entertainment\\r\\n\\r\\n                                    |                                     Search Engine Marketing Executive                                  \\r\\n\\r\\n\\r\\n                                \\n\\n',\n",
       " '\\n  15,000 - 25,000 p.m                               \\r\\n                                 | \\r\\n                                Under Graduate  \\r\\n\\r\\n\\r\\n                                                                  \\r\\n\\r\\n\\r\\n                                  \\r\\n\\r\\n                                  |   Chennai \\r\\n\\r\\n                              \\r\\n\\r\\n                            ',\n",
       " '\\n Anna nagar                               \\r\\n                               ',\n",
       " '\\n\\r\\n                             Gender :  All                              \\r\\n                               | Age Limit  - 20-30  | Openings - 3 | Experience - 0-1 Year                            \\r\\n                            ',\n",
       " '  15,000 - 25,000    |    Media & Entertainment ',\n",
       " '  15,000 - 25,000    |    Media & Entertainment ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the contents from the <div> tags\n",
    "all_divs = res_1.find_all('div',class_ = 'location')\n",
    "conts = [div.text for div in all_divs]\n",
    "conts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbabca2",
   "metadata": {},
   "source": [
    "**Yet again, we clean each element of the above list using the `clean_text()` function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddfa0e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Media & Entertainment | Search Engine Marketing Executive',\n",
       " '15,000 - 25,000 p.m | Under Graduate | Chennai',\n",
       " 'Anna nagar',\n",
       " 'Gender : All | Age Limit - 20-30 | Openings - 3 | Experience - 0-1 Year',\n",
       " '15,000 - 25,000 | Media & Entertainment',\n",
       " '15,000 - 25,000 | Media & Entertainment']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean each retrieved data using the clean_text() function\n",
    "conts = [clean_text(cont) for cont in conts]\n",
    "conts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b42bab",
   "metadata": {},
   "source": [
    "**We split the contents by the colon ':' and store it in a new variable `temps`.  \n",
    "And we store the needed contents from the `temps` in a new list `cleaned_conts`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88fce7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Media & Entertainment', 'Search Engine Marketing Executive'],\n",
       " ['15,000 - 25,000 p.m', 'Under Graduate', 'Chennai'],\n",
       " ['Anna nagar'],\n",
       " ['Gender : All',\n",
       "  'Age Limit - 20-30',\n",
       "  'Openings - 3',\n",
       "  'Experience - 0-1 Year'],\n",
       " ['15,000 - 25,000', 'Media & Entertainment'],\n",
       " ['15,000 - 25,000', 'Media & Entertainment']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the needed contents in a list\n",
    "cleaned_conts = [] \n",
    "\n",
    "for cont in conts:\n",
    "    # temps store the splitted elements\n",
    "    temps = cont.split('|')\n",
    "    temps = [temp.strip() for temp in temps]\n",
    "    cleaned_conts.append(temps)\n",
    "cleaned_conts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0c33a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : All\n",
      "Age Limit - 20-30\n",
      "Openings - 3\n",
      "Experience - 0-1 Year\n"
     ]
    }
   ],
   "source": [
    "# Printing the requirements content\n",
    "for cont in cleaned_conts[3]:\n",
    "    print(cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab20a5",
   "metadata": {},
   "source": [
    "**We get 2D array `cleaned_conts` having the necessary informations. Since the last element is the 'Requirement' which is different for each job, We will deal it with it.**  \n",
    "  \n",
    "**By different means,  \n",
    "For Example,  \n",
    "Job-1 might have gender and age while Job-2 might have only the age in their requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11aebb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : All, Age : 20-30, Openings : 3, Experience : 0-1 Year\n"
     ]
    }
   ],
   "source": [
    "for cont in cleaned_conts[3]:\n",
    "    if cont.startswith('Gender :'):\n",
    "        gender = cont[9:]\n",
    "    if cont.startswith('Age Limit -'):\n",
    "        age = cont[12:]\n",
    "    if cont.startswith('Openings -'):\n",
    "        opening = cont[11:]\n",
    "    if cont.startswith('Experience - '):\n",
    "        exp = cont[13:]\n",
    "print(f\"Gender : {gender}, Age : {age}, Openings : {opening}, Experience : {exp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef6c4e",
   "metadata": {},
   "source": [
    "**Similarly we store every value from the `cleaned_conts` to its corresponding variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "378a103c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field = Media & Entertainment, Description : Search Engine Marketing Executive\n"
     ]
    }
   ],
   "source": [
    "field, desc = map(str, cleaned_conts[0])\n",
    "print(f\"Field = {field}, Description : {desc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "659c492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary = 15,000 - 25,000 p.m, Qualification : Under Graduate, City = Chennai\n"
     ]
    }
   ],
   "source": [
    "sal, qual, city = map(str,cleaned_conts[1])\n",
    "print(f\"Salary = {sal}, Qualification : {qual}, City = {city}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a28b9be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmark : ['Anna nagar']\n"
     ]
    }
   ],
   "source": [
    "landmark = cleaned_conts[2]\n",
    "print(f\"Landmark : {landmark}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc5e8d",
   "metadata": {},
   "source": [
    "**Now, since we retrived all the necessary contents from this webpage, we will consolidate Step 5.3 using a function \n",
    "`scrap_info()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fa9837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_info(response):\n",
    "    # This function is used to retrieve the information from the child web-pages\n",
    "    gender = age = opening = exp = city = landmark = field = desc = sal = qual = \" \"\n",
    "    \n",
    "    # Get the contents from the <div> tags\n",
    "    all_divs = response.find_all('div',class_ = 'location')\n",
    "    \n",
    "    conts = [div.text for div in all_divs]\n",
    "    # Clean each retrieved data using the clean_text() function\n",
    "    \n",
    "    conts = [clean_text(cont) for cont in conts]\n",
    "    # Store the needed contents in a list\n",
    "    cleaned_conts = [] \n",
    "\n",
    "    for cont in conts:\n",
    "        # temps store the splitted elements\n",
    "        temps = cont.split('|')\n",
    "        \n",
    "        temps = [temp.strip() for temp in temps]\n",
    "        cleaned_conts.append(temps) \n",
    "        \n",
    "    field, desc = map(str, cleaned_conts[0])   \n",
    "    sal, qual, city = map(str,cleaned_conts[1])\n",
    "    landmark = str(cleaned_conts[2][0])\n",
    "    \n",
    "    for cont in cleaned_conts[3]:\n",
    "        if cont.startswith('Gender :'):\n",
    "            gender = cont[9:]\n",
    "        if cont.startswith('Age Limit -'):\n",
    "            age = cont[12:]\n",
    "        if cont.startswith('Openings -'):\n",
    "            opening = cont[11:]\n",
    "        if cont.startswith('Experience - '):\n",
    "            exp = cont[13:]\n",
    "    \n",
    "    return (gender,age,opening,exp,city,landmark,desc,sal,qual,field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7eed9bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('All',\n",
       " '20-30',\n",
       " '3',\n",
       " '0-1 Year',\n",
       " 'Chennai',\n",
       " 'Anna nagar',\n",
       " 'Search Engine Marketing Executive',\n",
       " '15,000 - 25,000 p.m',\n",
       " 'Under Graduate',\n",
       " 'Media & Entertainment')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping the information for the first url in the home webpage\n",
    "scrap_info(res_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8093cc26",
   "metadata": {},
   "source": [
    "### STEP 5.4 : Extending to all URLs in a single webpage\n",
    "Now, as we have done it for a single url, we will extend it to all the urls in a single webpage that is stored in the variable `href`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d22f6be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_info(href):\n",
    "    # This function gets the urls from the get_href() function and retreives the data\n",
    "    \n",
    "    # The info_list is used to store all the acquired data\n",
    "    info_list = []\n",
    "    for url in href:\n",
    "        # Request and parse each url and append the information to the info_list\n",
    "        res_1 = parse(url)\n",
    "        # Appending the scraped content to the info_list using the scrap_info() function\n",
    "        info_list.append(scrap_info(res_1))\n",
    "        \n",
    "    # Convert the list to a np.array() and get the transpose to group each attributes\n",
    "    info_list = (np.array(info_list)).T\n",
    "    return info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73a23334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['All'],\n",
       "       ['20-30'],\n",
       "       ['3'],\n",
       "       ['0-1 Year'],\n",
       "       ['Chennai'],\n",
       "       ['Anna nagar'],\n",
       "       ['Search Engine Marketing Executive'],\n",
       "       ['15,000 - 25,000 p.m'],\n",
       "       ['Under Graduate'],\n",
       "       ['Media & Entertainment']], dtype='<U33')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_info([url_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70984841",
   "metadata": {},
   "source": [
    "### STEP 5.5 : Retrieving other infomations\n",
    "In this step, we will other data(s) like the job posted date and the end date, company name, required employee's description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf85b2c",
   "metadata": {},
   "source": [
    "Since, all the other data(s) that we are looking for are present in the `<div>` tag with the class name `<companyName`, we will retreive the same way that we retreived data in the above process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f4f0b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tSearch Engine Marketing Executive\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t| \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tSri global innovatiion\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tPosted Date : 22-10-2023   | Open Until : 29-11-2023',\n",
       " '\\n  Dealership Sales and Value Added Services Executive\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGraphic Designer\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t| \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tC2S ENTERPRISES\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tPosted Date : 17-11-2023   | Open Until : 29-11-2023',\n",
       " '\\n  Animator | Assistant Graphic Designer | Graphic Designer | Social Media & Digital Marketing Manager\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tActor\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t| \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tC2S ENTERPRISES\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tPosted Date : 17-11-2023   | Open Until : 29-11-2023',\n",
       " '\\n  Actor | Marketing and Social Media manager | Social Media & Digital Marketing Manager | Social Media Executive | Storyboard Artist\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tCaptain\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t| \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tSri global innovatiion\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tPosted Date : 21-11-2023   | Open Until : 29-11-2023',\n",
       " '\\n  Transport Coordinator\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tElectrical Design Developer\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t| \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tSRG POWER CONTROL SYSTEM\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tPosted Date : 25-07-2023   | Open Until : 30-11-2023',\n",
       " '\\n  Electrical Design Developer\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tBilling Executive\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t| \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tSI Automobiles\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tPosted Date : 31-08-2023   | Open Until : 30-11-2023',\n",
       " '\\n  Accounts Executive | Billing Executive\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tSpecialized Sewing Machine Operator\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t| \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tTalentpro India HR Private Limited\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tPosted Date : 06-09-2023   | Open Until : 30-11-2023',\n",
       " '\\n  Sewing Machine Operator\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tExecutive Engineer\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t| \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tANNAI INFRA DEVELOPERS LIMITED\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tPosted Date : 11-09-2023   | Open Until : 30-11-2023',\n",
       " '\\n  Construction Laboratory & Field Technician | Construction Technician (Civil)- Wind Power Plant\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tSoftware Developer\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t| \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDarus infotech india pvt ltd\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tPosted Date : 12-09-2023   | Open Until : 30-11-2023',\n",
       " '\\n  Editor | Graphic Designer\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tAssociate - Desktop Publishing (DTP)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t| \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDarus infotech india pvt ltd\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\n',\n",
       " '\\n\\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tPosted Date : 12-09-2023   | Open Until : 30-11-2023',\n",
       " '\\n  Director of Photography | Editor | Graphic Designer\\t\\t\\t\\t\\t\\t\\t\\t \\n']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving other information using the div tag\n",
    "all_div = response.find_all(\"div\",class_ = 'companyName')\n",
    "all_datas = [div.text for div in all_div]\n",
    "all_datas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef6b5ac",
   "metadata": {},
   "source": [
    "**Ufffff!!!!  \n",
    "The Same story!   \n",
    "Clean it using the `clean_text()` function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fab2f240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Search Engine Marketing Executive | Sri global innovatiion',\n",
       " 'Posted Date : 22-10-2023 | Open Until : 29-11-2023',\n",
       " 'Dealership Sales and Value Added Services Executive',\n",
       " 'Graphic Designer | C2S ENTERPRISES',\n",
       " 'Posted Date : 17-11-2023 | Open Until : 29-11-2023',\n",
       " 'Animator | Assistant Graphic Designer | Graphic Designer | Social Media & Digital Marketing Manager',\n",
       " 'Actor | C2S ENTERPRISES',\n",
       " 'Posted Date : 17-11-2023 | Open Until : 29-11-2023',\n",
       " 'Actor | Marketing and Social Media manager | Social Media & Digital Marketing Manager | Social Media Executive | Storyboard Artist',\n",
       " 'Captain | Sri global innovatiion',\n",
       " 'Posted Date : 21-11-2023 | Open Until : 29-11-2023',\n",
       " 'Transport Coordinator',\n",
       " 'Electrical Design Developer | SRG POWER CONTROL SYSTEM',\n",
       " 'Posted Date : 25-07-2023 | Open Until : 30-11-2023',\n",
       " 'Electrical Design Developer',\n",
       " 'Billing Executive | SI Automobiles',\n",
       " 'Posted Date : 31-08-2023 | Open Until : 30-11-2023',\n",
       " 'Accounts Executive | Billing Executive',\n",
       " 'Specialized Sewing Machine Operator | Talentpro India HR Private Limited',\n",
       " 'Posted Date : 06-09-2023 | Open Until : 30-11-2023',\n",
       " 'Sewing Machine Operator',\n",
       " 'Executive Engineer | ANNAI INFRA DEVELOPERS LIMITED',\n",
       " 'Posted Date : 11-09-2023 | Open Until : 30-11-2023',\n",
       " 'Construction Laboratory & Field Technician | Construction Technician (Civil)- Wind Power Plant',\n",
       " 'Software Developer | Darus infotech india pvt ltd',\n",
       " 'Posted Date : 12-09-2023 | Open Until : 30-11-2023',\n",
       " 'Editor | Graphic Designer',\n",
       " 'Associate - Desktop Publishing (DTP) | Darus infotech india pvt ltd',\n",
       " 'Posted Date : 12-09-2023 | Open Until : 30-11-2023',\n",
       " 'Director of Photography | Editor | Graphic Designer']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_datas = [clean_text(data) for data in all_datas]\n",
    "all_datas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e34ca",
   "metadata": {},
   "source": [
    "**From the above step, it is clear that the `all_datas` contains the information that we are looking for.  \n",
    "We now manipulate the above list to retrieve the data.**\n",
    "  \n",
    "**Since all the dates are present every third line from the second line, we get them by the following**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f48dbc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the post_date and the last_date to apply\n",
    "post_date = [] \n",
    "last_date = []\n",
    "\n",
    "for i in range(1,len(all_datas),3):\n",
    "    post, last = map(str,all_datas[i].split('|'))\n",
    "    \n",
    "    post_date.append(post)\n",
    "    last_date.append(last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ba2af5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post date : ['Posted Date : 22-10-2023 ', 'Posted Date : 17-11-2023 ', 'Posted Date : 17-11-2023 ', 'Posted Date : 21-11-2023 ', 'Posted Date : 25-07-2023 ', 'Posted Date : 31-08-2023 ', 'Posted Date : 06-09-2023 ', 'Posted Date : 11-09-2023 ', 'Posted Date : 12-09-2023 ', 'Posted Date : 12-09-2023 ']\n",
      "\n",
      "Last date : [' Open Until : 29-11-2023', ' Open Until : 29-11-2023', ' Open Until : 29-11-2023', ' Open Until : 29-11-2023', ' Open Until : 30-11-2023', ' Open Until : 30-11-2023', ' Open Until : 30-11-2023', ' Open Until : 30-11-2023', ' Open Until : 30-11-2023', ' Open Until : 30-11-2023']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Post date : {post_date}\\n\")\n",
    "print(f\"Last date : {last_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e8ead8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the text from the dates\n",
    "post_date = [post.split(':')[1] for post in post_date]\n",
    "last_date = [last.split(':')[1] for last in last_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4afeba8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post date : [' 22-10-2023 ', ' 17-11-2023 ', ' 17-11-2023 ', ' 21-11-2023 ', ' 25-07-2023 ', ' 31-08-2023 ', ' 06-09-2023 ', ' 11-09-2023 ', ' 12-09-2023 ', ' 12-09-2023 ']\n",
      "\n",
      "Last date : [' 29-11-2023', ' 29-11-2023', ' 29-11-2023', ' 29-11-2023', ' 30-11-2023', ' 30-11-2023', ' 30-11-2023', ' 30-11-2023', ' 30-11-2023', ' 30-11-2023']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Post date : {post_date}\\n\")\n",
    "print(f\"Last date : {last_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c4688",
   "metadata": {},
   "source": [
    "**All the Company name are present every third line from the first line, we get them by the following**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5b2479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the company name\n",
    "company_name = []\n",
    "\n",
    "for i in range(0,len(all_datas),3):\n",
    "    # temp variable is used to store the unwanted data when we split the lists\n",
    "    temp, name = map(str,all_datas[i].split('|'))\n",
    "    \n",
    "    company_name.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1844f886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Sri global innovatiion',\n",
       " ' C2S ENTERPRISES',\n",
       " ' C2S ENTERPRISES',\n",
       " ' Sri global innovatiion',\n",
       " ' SRG POWER CONTROL SYSTEM',\n",
       " ' SI Automobiles',\n",
       " ' Talentpro India HR Private Limited',\n",
       " ' ANNAI INFRA DEVELOPERS LIMITED',\n",
       " ' Darus infotech india pvt ltd',\n",
       " ' Darus infotech india pvt ltd']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5d272",
   "metadata": {},
   "source": [
    "**Finally in the Scraping process, we will get the roles information from the `all_datas` which are present every third line from second line.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48d88389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dealership Sales and Value Added Services Executive',\n",
       " 'Animator | Assistant Graphic Designer | Graphic Designer | Social Media & Digital Marketing Manager',\n",
       " 'Actor | Marketing and Social Media manager | Social Media & Digital Marketing Manager | Social Media Executive | Storyboard Artist',\n",
       " 'Transport Coordinator',\n",
       " 'Electrical Design Developer',\n",
       " 'Accounts Executive | Billing Executive',\n",
       " 'Sewing Machine Operator',\n",
       " 'Construction Laboratory & Field Technician | Construction Technician (Civil)- Wind Power Plant',\n",
       " 'Editor | Graphic Designer',\n",
       " 'Director of Photography | Editor | Graphic Designer']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the roles needed for each job\n",
    "roles = []\n",
    "\n",
    "for i in range(2,len(all_datas),3):\n",
    "    role = all_datas[i]\n",
    "    \n",
    "    roles.append(role)\n",
    "roles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4a2e38",
   "metadata": {},
   "source": [
    "**Consolidating the Step 5.5 using the function `scrap_add_data()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cf8073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_add_data(response):\n",
    "    # This function is to get all the additional information from the main webpage\n",
    "    post_date = [] \n",
    "    last_date = []\n",
    "    roles = []\n",
    "    company_name = []\n",
    "    \n",
    "    # Retrieving other information\n",
    "    all_div = response.find_all(\"div\",class_ = 'companyName')\n",
    "    all_datas = [div.text for div in all_div]\n",
    "    all_datas = [clean_text(data) for data in all_datas]\n",
    "\n",
    "    # Retrieving the post_date and the last_date to apply\n",
    "    for i in range(1,len(all_datas),3):\n",
    "        post, last = map(str,all_datas[i].split('|'))\n",
    "        post_date.append(post)\n",
    "        last_date.append(last)\n",
    "    \n",
    "    # Removing the text from the dates\n",
    "    post_date = [post.split(':')[1] for post in post_date]\n",
    "    last_date = [last.split(':')[1] for last in last_date]\n",
    "\n",
    "    # Retrieving the company name\n",
    "    for i in range(0,len(all_datas),3):    \n",
    "        # temp variable is used to store the unwanted data when we split the lists\n",
    "        temp, name = map(str,all_datas[i].split('|'))\n",
    "        company_name.append(name)\n",
    "        \n",
    "    # Retrieving the roles needed for each job\n",
    "    for i in range(2,len(all_datas),3):\n",
    "        role = all_datas[i]\n",
    "        roles.append(role)\n",
    "    \n",
    "    return (post_date,last_date,roles,company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ef9cd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([' 22-10-2023 ',\n",
       "  ' 17-11-2023 ',\n",
       "  ' 17-11-2023 ',\n",
       "  ' 21-11-2023 ',\n",
       "  ' 25-07-2023 ',\n",
       "  ' 31-08-2023 ',\n",
       "  ' 06-09-2023 ',\n",
       "  ' 11-09-2023 ',\n",
       "  ' 12-09-2023 ',\n",
       "  ' 12-09-2023 '],\n",
       " [' 29-11-2023',\n",
       "  ' 29-11-2023',\n",
       "  ' 29-11-2023',\n",
       "  ' 29-11-2023',\n",
       "  ' 30-11-2023',\n",
       "  ' 30-11-2023',\n",
       "  ' 30-11-2023',\n",
       "  ' 30-11-2023',\n",
       "  ' 30-11-2023',\n",
       "  ' 30-11-2023'],\n",
       " ['Dealership Sales and Value Added Services Executive',\n",
       "  'Animator | Assistant Graphic Designer | Graphic Designer | Social Media & Digital Marketing Manager',\n",
       "  'Actor | Marketing and Social Media manager | Social Media & Digital Marketing Manager | Social Media Executive | Storyboard Artist',\n",
       "  'Transport Coordinator',\n",
       "  'Electrical Design Developer',\n",
       "  'Accounts Executive | Billing Executive',\n",
       "  'Sewing Machine Operator',\n",
       "  'Construction Laboratory & Field Technician | Construction Technician (Civil)- Wind Power Plant',\n",
       "  'Editor | Graphic Designer',\n",
       "  'Director of Photography | Editor | Graphic Designer'],\n",
       " [' Sri global innovatiion',\n",
       "  ' C2S ENTERPRISES',\n",
       "  ' C2S ENTERPRISES',\n",
       "  ' Sri global innovatiion',\n",
       "  ' SRG POWER CONTROL SYSTEM',\n",
       "  ' SI Automobiles',\n",
       "  ' Talentpro India HR Private Limited',\n",
       "  ' ANNAI INFRA DEVELOPERS LIMITED',\n",
       "  ' Darus infotech india pvt ltd',\n",
       "  ' Darus infotech india pvt ltd'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrap_add_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a5e6c5",
   "metadata": {},
   "source": [
    "### STEP 6 : Updating the Data\n",
    "We will update all the data that we retrieved during Step - 5 in a dictionary and then in a `pandas-DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711315a7",
   "metadata": {},
   "source": [
    "We will now use all the functions that we created during our journey\n",
    "- `parse()`\n",
    "- `scrap_title()`\n",
    "- `get_href()`\n",
    "- `clean_text()`\n",
    "- `scrap_info()`\n",
    "- `ret_info()`\n",
    "- `scrap_add_data()`\n",
    "  \n",
    "We will create a dictionary to store all the above data for a single webpage\n",
    "\n",
    "> Remember: All we done until now is only for the `base_url`, uffff, we need to extend it to all the webpage in the `urls`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a59116aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise all the list to store the required data(s)\n",
    "job_title = []\n",
    "gender = []\n",
    "age = []\n",
    "opening = []\n",
    "exp = []\n",
    "city = []\n",
    "landmark = []\n",
    "field = []\n",
    "desc = []\n",
    "sal = []\n",
    "qual = []\n",
    "post_date = [] \n",
    "last_date = []\n",
    "roles = []\n",
    "company_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9c69993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.tnprivatejobs.tn.gov.in/Home/jobs'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = base_url\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d82f3c4",
   "metadata": {},
   "source": [
    "### Appending functions \n",
    "2 Appending function to append the scraped content into their respective lists (from - homepage `append_data()`, childpage `append_add_data()`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1323dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data(info):\n",
    "    # This function is used to append the data scraped from the each child webpage into the respective variable\n",
    "    [gender.append(i) for i in info[0]]\n",
    "    [age.append(i) for i in info[1]]\n",
    "    [opening.append(i) for i in info[2]]\n",
    "    [exp.append(i) for i in info[3]]\n",
    "    [city.append(i) for i in info[4]]    \n",
    "    [landmark.append(i) for i in info[5]]    \n",
    "    [desc.append(i) for i in info[6]]\n",
    "    [sal.append(i) for i in info[7]]\n",
    "    [qual.append(i) for i in info[8]]\n",
    "    [field.append(i) for i in info[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "10ae4ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_add_data(info):\n",
    "    # This function is used to append the data scraped to their respective variables\n",
    "    [post_date.append(i) for i in info[0]]\n",
    "    [last_date.append(i) for i in info[1]]\n",
    "    [roles.append(i) for i in info[2]]\n",
    "    [company_name.append(i) for i in info[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dcf548",
   "metadata": {},
   "source": [
    "### Main Function \n",
    "Main function `scrap_webpage()`to scrap the contents of the job posting webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e175ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_webpage(url):\n",
    "    # Request and Parse the URL\n",
    "    response = parse(url)\n",
    "    \n",
    "    # Get the child URLs for each job using the get_href() function\n",
    "    hrefs = get_href(response)\n",
    "    \n",
    "    # Retrieve all the information from each urls using the ret_info() and scrap_info() function\n",
    "    all_info = ret_info(hrefs)\n",
    "    # append all the data using the append_data() function\n",
    "    append_data(all_info)\n",
    "    \n",
    "    # Retrieve other additional information from the main webpages\n",
    "    all_add_info = scrap_add_data(response)\n",
    "    # append it using the append_add_data() function\n",
    "    append_add_data(all_add_info)\n",
    "    \n",
    "    [job_title.append(i) for i in scrap_title(response)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af79a68f",
   "metadata": {},
   "source": [
    "### Scraping through the entire webpages\n",
    "Now doing web-scraping for all the pages in the urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c56e4bd",
   "metadata": {},
   "source": [
    "> Execute the below lines for scraping through the entire webpages to scrap the contents\n",
    "\n",
    "\n",
    "![](https://imgur.com/KR2wVXH.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d803bcfe",
   "metadata": {},
   "source": [
    "### Dictionary\n",
    "Convert the acquired data into a dictionary `dic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "676c215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the acquired data into a dictionary\n",
    "dic = {\n",
    "    \"Job Title\" : job_title,\n",
    "    \"Description\" : desc,\n",
    "    \"Field\" : field,\n",
    "    \"Company Name\" : company_name,\n",
    "    \"City\" : city,\n",
    "    \"Landmark\" : landmark,\n",
    "    \"Post Date\" : post_date, \n",
    "    \"Last Date\" : last_date,\n",
    "    \"Salary\" : sal,\n",
    "    \"Gender\" : gender,\n",
    "    \"Age\" : age,\n",
    "    \"Experience\" : exp,\n",
    "    \"Qualification\" : qual,\n",
    "    \"Roles\" : roles,\n",
    "    \"Openings\" : opening\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c611aa6",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "After having created a dictionary, we will now create a Pandas dataframe `df` for easy viewing of the acquired data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08f40ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a table using the DataFrame function of the pandas library for easy viewing\n",
    "df = pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4349c262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Field</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>City</th>\n",
       "      <th>Landmark</th>\n",
       "      <th>Post Date</th>\n",
       "      <th>Last Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Roles</th>\n",
       "      <th>Openings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digital Marketing Executive</td>\n",
       "      <td>Search Engine Marketing Executive</td>\n",
       "      <td>Media &amp; Entertainment</td>\n",
       "      <td>Sri global innovatiion</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Anna nagar</td>\n",
       "      <td>22-10-2023</td>\n",
       "      <td>29-11-2023</td>\n",
       "      <td>15,000 - 25,000 p.m</td>\n",
       "      <td>All</td>\n",
       "      <td>20-30</td>\n",
       "      <td>0-1 Year</td>\n",
       "      <td>Under Graduate</td>\n",
       "      <td>Dealership Sales and Value Added Services Exec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Graphic Desginer</td>\n",
       "      <td>Graphic Designer</td>\n",
       "      <td>Media &amp; Entertainment</td>\n",
       "      <td>C2S ENTERPRISES</td>\n",
       "      <td>Salem</td>\n",
       "      <td>SALEM</td>\n",
       "      <td>17-11-2023</td>\n",
       "      <td>29-11-2023</td>\n",
       "      <td>10,000 - 15,000 p.m</td>\n",
       "      <td>All</td>\n",
       "      <td>18-32</td>\n",
       "      <td>Fresher</td>\n",
       "      <td>Under Graduate</td>\n",
       "      <td>Animator | Assistant Graphic Designer | Graphi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VIDEO JOCKEY</td>\n",
       "      <td>Actor</td>\n",
       "      <td>Media &amp; Entertainment</td>\n",
       "      <td>C2S ENTERPRISES</td>\n",
       "      <td>Salem</td>\n",
       "      <td>SALEM</td>\n",
       "      <td>17-11-2023</td>\n",
       "      <td>29-11-2023</td>\n",
       "      <td>10,000 - 15,000 p.m</td>\n",
       "      <td>All</td>\n",
       "      <td>18-25</td>\n",
       "      <td>Fresher</td>\n",
       "      <td>Under Graduate - Bachelor of Arts , Bachelor o...</td>\n",
       "      <td>Actor | Marketing and Social Media manager | S...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bus Captain</td>\n",
       "      <td>Captain</td>\n",
       "      <td>Tourism &amp; Hospitality</td>\n",
       "      <td>Sri global innovatiion</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>koyambedu</td>\n",
       "      <td>21-11-2023</td>\n",
       "      <td>29-11-2023</td>\n",
       "      <td>15,000 - 25,000 p.m</td>\n",
       "      <td>Male</td>\n",
       "      <td>18-35</td>\n",
       "      <td>Fresher</td>\n",
       "      <td>SSLC</td>\n",
       "      <td>Transport Coordinator</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Electrical design engineer</td>\n",
       "      <td>Electrical Design Developer</td>\n",
       "      <td>Electronics &amp; Hardware</td>\n",
       "      <td>SRG POWER CONTROL SYSTEM</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>641107</td>\n",
       "      <td>25-07-2023</td>\n",
       "      <td>30-11-2023</td>\n",
       "      <td>10,000 - 15,000 p.m</td>\n",
       "      <td>All</td>\n",
       "      <td>18-35</td>\n",
       "      <td>Fresher</td>\n",
       "      <td>Under Graduate - Bachelor of Engineering / Tec...</td>\n",
       "      <td>Electrical Design Developer</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Job Title                        Description  \\\n",
       "0  Digital Marketing Executive  Search Engine Marketing Executive   \n",
       "1             Graphic Desginer                   Graphic Designer   \n",
       "2                 VIDEO JOCKEY                              Actor   \n",
       "3                  Bus Captain                            Captain   \n",
       "4   Electrical design engineer        Electrical Design Developer   \n",
       "\n",
       "                    Field               Company Name        City    Landmark  \\\n",
       "0   Media & Entertainment     Sri global innovatiion     Chennai  Anna nagar   \n",
       "1   Media & Entertainment            C2S ENTERPRISES       Salem       SALEM   \n",
       "2   Media & Entertainment            C2S ENTERPRISES       Salem       SALEM   \n",
       "3   Tourism & Hospitality     Sri global innovatiion     Chennai   koyambedu   \n",
       "4  Electronics & Hardware   SRG POWER CONTROL SYSTEM  Coimbatore      641107   \n",
       "\n",
       "      Post Date    Last Date               Salary Gender    Age Experience  \\\n",
       "0   22-10-2023    29-11-2023  15,000 - 25,000 p.m    All  20-30   0-1 Year   \n",
       "1   17-11-2023    29-11-2023  10,000 - 15,000 p.m    All  18-32    Fresher   \n",
       "2   17-11-2023    29-11-2023  10,000 - 15,000 p.m    All  18-25    Fresher   \n",
       "3   21-11-2023    29-11-2023  15,000 - 25,000 p.m   Male  18-35    Fresher   \n",
       "4   25-07-2023    30-11-2023  10,000 - 15,000 p.m    All  18-35    Fresher   \n",
       "\n",
       "                                       Qualification  \\\n",
       "0                                     Under Graduate   \n",
       "1                                     Under Graduate   \n",
       "2  Under Graduate - Bachelor of Arts , Bachelor o...   \n",
       "3                                               SSLC   \n",
       "4  Under Graduate - Bachelor of Engineering / Tec...   \n",
       "\n",
       "                                               Roles Openings  \n",
       "0  Dealership Sales and Value Added Services Exec...        3  \n",
       "1  Animator | Assistant Graphic Designer | Graphi...        5  \n",
       "2  Actor | Marketing and Social Media manager | S...        4  \n",
       "3                              Transport Coordinator       30  \n",
       "4                        Electrical Design Developer        5  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a8139",
   "metadata": {},
   "source": [
    "### STEP 7 : Storing the acquired data\n",
    "We will store the data acquired during this web-scraping tutorial in a CSV file using the pandas' `to_csv()` function  \n",
    "  \n",
    "We will store the contents in the file `job_postings.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d1e4927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the contents of the DataFrame df to a file\n",
    "df.to_csv('job_postings.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e580a",
   "metadata": {},
   "source": [
    "![](https://imgur.com/udNnm9r.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867a4e3f",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440591c2",
   "metadata": {},
   "source": [
    "In conclusion, the web scraping project focused on extracting job postings from the Government of Tamil Nadu's official webpage has been successfully implemented using BeautifulSoup in Python. By harnessing the power of web scraping, we've created a streamlined process for accessing crucial employment information. It is essential to note that the project adheres to ethical scraping practices, respecting the terms of use of the government portal. The implementation of Beautiful Soup proves to be effective in parsing HTML, making the project a valuable resource for those seeking government job opportunities in Tamil Nadu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc63d6",
   "metadata": {},
   "source": [
    "**_Now we have come to the end of this tutorial, and hope you all learned the basics of web-scraping in detail. Till next tutorial, peace out......._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16213843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sayonara!!!\n"
     ]
    }
   ],
   "source": [
    "print('Sayonara!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0b955c",
   "metadata": {},
   "source": [
    "<h1><center>THE END !!!</center></h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
